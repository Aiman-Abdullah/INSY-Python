{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Which stock are you interested in: \n",
      "\n",
      "Most Actives :\n",
      "GE General Electric Co\n",
      "BAC Bank of America Corp\n",
      "CCL Carnival Corp\n",
      "OXY Occidental Petroleum Corp\n",
      "F Ford Motor Co\n",
      "WFC Wells Fargo & Co\n",
      "MRO Marathon Oil Corp\n",
      "T AT&T Inc\n",
      "PFE Pfizer Inc\n",
      "NCLH Norwegian Cruise Line Holdings Ltd\n",
      "\n",
      "\n",
      "\n",
      "Gainers :\n",
      "OXY Occidental Petroleum Corp\n",
      "MRO Marathon Oil Corp\n",
      "EOG EOG Resources Inc\n",
      "FTI TechnipFMC PLC\n",
      "DVN Devon Energy Corp\n",
      "NOV National Oilwell Varco Inc\n",
      "PXD Pioneer Natural Resources Co\n",
      "HAL Halliburton Co\n",
      "COP ConocoPhillips\n",
      "CXO Concho Resources Inc\n",
      "\n",
      "\n",
      "\n",
      "Losers :\n",
      "D Dominion Energy Inc\n",
      "SRE Sempra Energy\n",
      "PHM Pultegroup Inc\n",
      "CCI Crown Castle International Corp\n",
      "AWK American Water Works Company Inc\n",
      "HBI HanesBrands Inc\n",
      "LEN Lennar Corp\n",
      "RCL Royal Caribbean Cruises Ltd\n",
      "CMS CMS Energy Corp\n",
      "BA Boeing Co\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as uReq\n",
    "import csv\n",
    "\n",
    "\n",
    "def main():\n",
    "    url_Tickers = 'https://money.cnn.com/data/hotstocks/'\n",
    "    firstTable_diction = dict()  # Hold Ticker name & Company name\n",
    "    secondTable_diction = dict()  # Hold Ticker name & Company name\n",
    "    thirdTable_diction = dict()  # Hold Ticker name & Company name\n",
    "    uClient = uReq(url_Tickers)\n",
    "    page_html = uClient.read()   # read all the page\n",
    "    uClient.close                  # Close after finish reading\n",
    "    page_html = soup(page_html,'html.parser') # Parser page to Html Languge\n",
    "    h3_list = list() # Store h3 values in a List\n",
    "\n",
    "\n",
    "# Loop through the html codes\n",
    "    for i in range(0, len(page_html) - 1):\n",
    "         most_Activity = page_html.find(id='wsod_hotStocks').find_all('h3')[i].string  # Extract  MostActives , Gainers , Losers  Words\n",
    "         h3_list.append(most_Activity)\n",
    "\n",
    "    search_location =0\n",
    "    while search_location<3:\n",
    "        tr_table = page_html.find_all(class_='wsod_dataTable wsod_dataTableBigAlt')[search_location]  # this line is take each table between the 3 tables\n",
    "        parameter =1\n",
    "        while True:\n",
    "            s=tr_table.find_all('tr')[parameter]        # take first tr in the first table start from 1 not 0\n",
    "            td_table =s.find_all('td')[0]       # take first td inside tr which inside table\n",
    "            link_a = td_table.find_all('a')[0].text   # take the first link text inside first td\n",
    "            span_words =td_table.find_all('span')[0]    # Extract span\n",
    "            dd = span_words.contents[0]\n",
    "            if search_location ==0:\n",
    "                firstTable_diction[link_a] = dd\n",
    "                parameter =parameter+1\n",
    "                if  parameter ==11:\n",
    "                    search_location =search_location+1\n",
    "                    break\n",
    "            if search_location == 1:\n",
    "                secondTable_diction[link_a] = dd\n",
    "                parameter = parameter + 1\n",
    "                if parameter == 11:\n",
    "                    search_location = search_location + 1\n",
    "                    break\n",
    "            if search_location ==2:\n",
    "                thirdTable_diction[link_a] = dd\n",
    "                parameter = parameter + 1\n",
    "                if parameter == 11:\n",
    "                    search_location = search_location + 1\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "    # Get All Keys and Values of Each Diction (Contains Ticker name , Company Name)\n",
    "    ticker_MostActivity_part = list(firstTable_diction.keys())\n",
    "    ticker_MostActivity_companyNames = list(firstTable_diction.values())\n",
    "\n",
    "    ticker_Gainers_part = list(secondTable_diction.keys())\n",
    "    ticker_Gainers_companyNames = list(secondTable_diction.values())\n",
    "\n",
    "    ticker_losers_part = list(thirdTable_diction.keys())\n",
    "    ticker_losers_companyNames = list(thirdTable_diction.values())\n",
    "\n",
    "\n",
    "\n",
    "    most_Actitvity_dict =dict()  # Hold Key as Ticker name Value Ticker Details from 2nd Page\n",
    "    Gainer_dict =dict()         # Hold Key as Ticker name Value Ticker Details from 2nd Page\n",
    "    losers_dict =dict()          # Hold Key as Ticker name Value Ticker Details from 2nd Page\n",
    "\n",
    "\n",
    "    # tickers will loop through all keys \"Tickers\" and open link to 2nd page of each Ticker and read all Stock info and store it in \"\"secondPage_details\"\"\n",
    "    #for tickers in range(len(list_all_Tickers)):  # has 3 indexes 0,1,2 each index has sub Tickers [0] = CCL,GE,BAC..  [1] = OXY,FTI,NOV... [2]=SRE,RCL,HBI....\n",
    "    for tickers in ticker_MostActivity_part:  # this will Check only Tickers of Most Activity\n",
    "            secondPage_details = dict()\n",
    "\n",
    "            # Must send each Ticker to check its details in 2nd Page\n",
    "            url = 'https://money.cnn.com/quote/quote.html?symb=' + tickers\n",
    "            uCCl = uReq(url)\n",
    "            page_html_CCl = uCCl.read()\n",
    "            uCCl.close\n",
    "            page_html_CCl = soup(page_html_CCl, 'html.parser')\n",
    "            collection_table = page_html_CCl.find_all(class_='wsod_dataTable wsod_dataTableBig')[0]\n",
    "            for i in range(len(collection_table)):\n",
    "                tr = collection_table.find_all('tr')[i]\n",
    "                td = tr.find_all('td')[0].text\n",
    "                td_span = tr.find_all('td')[1].text\n",
    "                secondPage_details[td] = td_span\n",
    "            most_Actitvity_dict[tickers] = secondPage_details\n",
    "    most_gategory =h3_list[0]\n",
    "    most_Activity_gategory =dict()\n",
    "    most_Activity_gategory[most_gategory] =firstTable_diction\n",
    "\n",
    "\n",
    "    list77 = list()\n",
    "    for kk, mm in most_Actitvity_dict.items():\n",
    "        for tt, pp in mm.items():\n",
    "            list77.append(pp)\n",
    "\n",
    "    tick_mostActivity_value = ''\n",
    "    comapnyName = ''\n",
    "    Previous_close = ''\n",
    "    Today_s_open = ''\n",
    "    Day_s_range = ''\n",
    "    Volume = ''\n",
    "    Average_volume = ''\n",
    "    Market_cap = ''\n",
    "\n",
    "    MostActivity = h3_list[0]\n",
    "    dimintion = len(list77)\n",
    "    counter2 = 0\n",
    "\n",
    "    csv_file = open('stocks.csv', 'w', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Categories', 'Tickers symbols', 'Stock name', 'Previous close', 'Today’s open', 'Day’s range', 'Volume','Average volume (3 months)', 'Market cap'])\n",
    "\n",
    "\n",
    "\n",
    "    # Start writting info into CSV file Row by Row\n",
    "    for i in range(0, len(ticker_MostActivity_part)):\n",
    "        tick_mostActivity_value = ticker_MostActivity_part[i]\n",
    "        comapnyName = ticker_MostActivity_companyNames[i]\n",
    "        while counter2 < dimintion:\n",
    "            Previous_close = list77[counter2]\n",
    "            Today_s_open = list77[counter2 + 1]\n",
    "            Day_s_range = list77[counter2 + 2]\n",
    "            Volume = list77[counter2 + 3]\n",
    "            Average_volume = list77[counter2 + 4]\n",
    "            Market_cap = list77[counter2 + 5]\n",
    "            counter2 = counter2 + 6\n",
    "            break\n",
    "\n",
    "        csv_writer.writerow([MostActivity,tick_mostActivity_value,comapnyName,Previous_close,Today_s_open,Day_s_range,Volume,Average_volume,Market_cap])\n",
    "\n",
    "    csv_file.close()\n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "    for tickers in ticker_Gainers_part:  # this will Check only Tickers of Gainer\n",
    "            secondPage_details = dict()\n",
    "\n",
    "            # Must send each Ticker to check its details in 2nd Page\n",
    "            url = 'https://money.cnn.com/quote/quote.html?symb=' + tickers\n",
    "            uCCl = uReq(url)\n",
    "            page_html_CCl = uCCl.read()\n",
    "            uCCl.close\n",
    "            page_html_CCl = soup(page_html_CCl, 'html.parser')\n",
    "            collection_table = page_html_CCl.find_all(class_='wsod_dataTable wsod_dataTableBig')[0]\n",
    "            for i in range(len(collection_table)):\n",
    "                tr = collection_table.find_all('tr')[i]\n",
    "                td = tr.find_all('td')[0].text\n",
    "                td_span = tr.find_all('td')[1].text\n",
    "                secondPage_details[td] = td_span\n",
    "            Gainer_dict[tickers] = secondPage_details\n",
    "    gainer_gategory = h3_list[1]\n",
    "    gainer_activity_gategory = dict()\n",
    "    gainer_activity_gategory[gainer_gategory] = secondTable_diction\n",
    "\n",
    "\n",
    "    list77 = list()\n",
    "    for kk, mm in Gainer_dict.items():\n",
    "        for tt, pp in mm.items():\n",
    "            list77.append(pp)\n",
    "\n",
    "    tick_gainer_value = ''\n",
    "    comapnyName = ''\n",
    "    Previous_close = ''\n",
    "    Today_s_open = ''\n",
    "    Day_s_range = ''\n",
    "    Volume = ''\n",
    "    Average_volume = ''\n",
    "    Market_cap = ''\n",
    "\n",
    "    gainer = h3_list[1]\n",
    "    dimintion = len(list77)\n",
    "    counter2 = 0\n",
    "\n",
    "    csv_file = open('stocks.csv', 'a', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Start append info into CSV file Row by Row\n",
    "    for i in range(0, len(ticker_Gainers_part)):\n",
    "        tick_gainer_value = ticker_Gainers_part[i]\n",
    "        comapnyName = ticker_Gainers_companyNames[i]\n",
    "        while counter2 < dimintion:\n",
    "            Previous_close = list77[counter2]\n",
    "            Today_s_open = list77[counter2 + 1]\n",
    "            Day_s_range = list77[counter2 + 2]\n",
    "            Volume = list77[counter2 + 3]\n",
    "            Average_volume = list77[counter2 + 4]\n",
    "            Market_cap = list77[counter2 + 5]\n",
    "            counter2 = counter2 + 6\n",
    "            break\n",
    "        csv_writer.writerow([gainer, tick_gainer_value, comapnyName, Previous_close, Today_s_open, Day_s_range, Volume,Average_volume, Market_cap])\n",
    "\n",
    "    csv_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for tickers in ticker_losers_part:  # this will Check only Tickers of Gainer\n",
    "            secondPage_details = dict()\n",
    "\n",
    "            # Must send each Ticker to check its details in 2nd Page\n",
    "            url = 'https://money.cnn.com/quote/quote.html?symb=' + tickers\n",
    "            uCCl = uReq(url)\n",
    "            page_html_CCl = uCCl.read()\n",
    "            uCCl.close\n",
    "            page_html_CCl = soup(page_html_CCl, 'html.parser')\n",
    "            collection_table = page_html_CCl.find_all(class_='wsod_dataTable wsod_dataTableBig')[0]\n",
    "            for i in range(len(collection_table)):\n",
    "                tr = collection_table.find_all('tr')[i]\n",
    "                td = tr.find_all('td')[0].text\n",
    "                td_span = tr.find_all('td')[1].text\n",
    "                secondPage_details[td] = td_span\n",
    "            losers_dict[tickers] = secondPage_details\n",
    "    loser_gategory = h3_list[2]\n",
    "    loser_activity_gategory = dict()\n",
    "    loser_activity_gategory[loser_gategory] = thirdTable_diction\n",
    "\n",
    "\n",
    "    list77 = list()\n",
    "    for kk,mm in losers_dict.items():\n",
    "        for tt, pp in mm.items():\n",
    "            list77.append(pp)\n",
    "\n",
    "    tick_loser_value =''\n",
    "    comapnyName=''\n",
    "    Previous_close =''\n",
    "    Today_s_open =''\n",
    "    Day_s_range= ''\n",
    "    Volume =''\n",
    "    Average_volume =''\n",
    "    Market_cap =''\n",
    "\n",
    "    losers=h3_list[2]\n",
    "    dimintion = len(list77)  # length = 60\n",
    "    counter2 = 0\n",
    "\n",
    "    csv_file = open('stocks.csv', 'a', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Start append info into CSV file Row by Row\n",
    "    for i in range(0,len(ticker_losers_part)):\n",
    "            tick_loser_value = ticker_losers_part[i]\n",
    "            comapnyName = ticker_losers_companyNames[i]\n",
    "            while counter2<dimintion:\n",
    "                Previous_close = list77[counter2]\n",
    "                Today_s_open=list77[counter2+1]\n",
    "                Day_s_range=list77[counter2+2]\n",
    "                Volume=list77[counter2+3]\n",
    "                Average_volume=list77[counter2+4]\n",
    "                Market_cap=list77[counter2+5]\n",
    "                counter2 =counter2+6\n",
    "                break\n",
    "            csv_writer.writerow([losers, tick_loser_value, comapnyName, Previous_close, Today_s_open, Day_s_range, Volume,Average_volume, Market_cap])\n",
    "\n",
    "    csv_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    check_value_in_lists = 0\n",
    "    print(\"Which stock are you interested in: \")\n",
    "\n",
    "    # Append All Ticker Symbol together\n",
    "    all_Ticker_Symbols = list()\n",
    "    all_Ticker_Symbols.append(ticker_MostActivity_part)\n",
    "    all_Ticker_Symbols.append(ticker_Gainers_part)\n",
    "    all_Ticker_Symbols.append(ticker_losers_part)\n",
    "    stop= True\n",
    "\n",
    "\n",
    "    # Print a list of Ticker Symbols and Company name to User of All Categories\n",
    "    while stop:\n",
    "        print()\n",
    "        for i in range(0, len(h3_list)):\n",
    "            if i == 0:\n",
    "                print(h3_list[i], ':')\n",
    "                for k, j in firstTable_diction.items():  # item will return key,value of each part of Dictionary\n",
    "                    print(k, j)  # i will print key , j will print values\n",
    "            print('')\n",
    "            if i == 1:\n",
    "                print(h3_list[i], ':')\n",
    "                for k, j in secondTable_diction.items():  # item will return key,value of each part of Dictionary\n",
    "                    print(k, j)  # i will print key , j will print values\n",
    "            print('')\n",
    "            if i == 2:\n",
    "                print(h3_list[i], ':')\n",
    "\n",
    "                for k, j in thirdTable_diction.items():  # item will return key,value of each part of Dictionary\n",
    "                    print(k, j)  # i will print key , j will print values\n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "        user_input = input(\"User inputs: \")\n",
    "\n",
    "    # loop through all Ticket Symbols and check matching with user input. If found stop searching and print result by calling print_result funtion\n",
    "        flag = True\n",
    "        counter =0\n",
    "        while flag:\n",
    "            if counter == 3:\n",
    "                break\n",
    "            for j in all_Ticker_Symbols[counter]:\n",
    "                if user_input == j:\n",
    "                    check_value_in_lists = check_value_in_lists + 1\n",
    "                    print_result(user_input)\n",
    "                    flag =False\n",
    "                    break\n",
    "            if flag == False:\n",
    "                break\n",
    "            counter = counter+1\n",
    "\n",
    "\n",
    "        if check_value_in_lists == 0:\n",
    "            print(\"The Company You entered Not Available in Stock, Enter Correct Company!\")\n",
    "\n",
    "        user_input = input(\"Finish extracting by Enter N Or Y to Continue: \")\n",
    "        while True:\n",
    "            if user_input.lower() == 'n':\n",
    "                stop =False\n",
    "                break\n",
    "            elif user_input.lower() == 'y':\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                user_input = input(\"Finish extracting by Enter N Or Y to Continue: \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This funtion is take input user\n",
    "open CSV file\n",
    "searching through the Rows for specific information \n",
    "if found stop searching & print results\n",
    "\"\"\"\n",
    "def print_result(user_input):\n",
    "\n",
    "    try:\n",
    "        file_handler = open('stocks.csv', 'r')\n",
    "        tick_value = ''\n",
    "        comapnyName = ''\n",
    "        Previous_close = ''\n",
    "        Today_s_open = ''\n",
    "        Day_s_range = ''\n",
    "        Volume = ''\n",
    "        Average_volume = ''\n",
    "        Market_cap = ''\n",
    "        data = csv.reader(file_handler)\n",
    "        for i in data:\n",
    "            looking_item = i[1]\n",
    "            if looking_item == user_input:\n",
    "                tick_value = i[1]\n",
    "                comapnyName = i[2]\n",
    "                Previous_close = i[3]\n",
    "                Today_s_open = i[4]\n",
    "                Day_s_range = i[5]\n",
    "                Volume = i[6]\n",
    "                Average_volume = i[7]\n",
    "                Market_cap = i[8]\n",
    "                break\n",
    "\n",
    "        print(\"The data for {} {} is the following:\".format(tick_value,comapnyName))\n",
    "        print(\"{} {}\".format(tick_value,comapnyName))\n",
    "        print(\"Previous_close:{}\".format(Previous_close))\n",
    "        print(\"Today_s_open:{}\".format(Today_s_open))\n",
    "        print(\"Day_s_range:{}\".format(Day_s_range))\n",
    "        print(\"Volume:{}\".format(Volume))\n",
    "        print(\"Average_volume:{}\".format(Average_volume))\n",
    "        print(\"Market_cap:{}\".format(Market_cap))\n",
    "        file_handler.close()\n",
    "\n",
    "    except:\n",
    "        print(\"Can not open The File\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fire main function\n",
    "if __name__ == '__main__':main()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
